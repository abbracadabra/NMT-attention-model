### an en-zh nmt model implemented with <a href='https://nlp.stanford.edu/pubs/emnlp15_attn.pdf'>Effective Approaches to Attention-based Neural Machine Translation</a>
#### model configuration
- glove50 word embedding for english language(vocab size 400000)
- <a href='https://github.com/Embedding/Chinese-Word-Vectors'>something i found</a> for chinese language word embedding(vocab size 20000)
- state size of 120
